{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAREA 2 : Grupo 8 (**Javier Muñoz de Torres y Álvaro Morán Lorente**)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datos**: Trabajaremos con un conjunto de datos del ambito de medicina/salud, concretamente en relación a problemas al corazón. Los datos vienen de la unión de otros 4 datasets procedentes de Cleveland; Hungary; Switzerland y VA Long Beach, y han sido tomados de pacientes de hospitales.\n",
    "\n",
    "**Base de datos**: [Heart Disease](https://archive.ics.uci.edu/dataset/45/heart+disease)<br>\n",
    "En el conjunto de datos el target `num` es categórica, por lo que nos centraremos en una tarea de clasificación. Tiene un rango (0,4), es decir, 5 posibles niveles, que indican de menor a mayor la presencia de un problema en el corazon. El objetivo de este análisis es clasificar los pacientes, dados los atributos que mostraremos a continuación, según \"la presencia de problemas\" de corazon, lo que se puede interpretar con \"como de probable es que tengas un problema de corazón\".\n",
    "\n",
    "**Interpretación del target:** <br>\n",
    "Para darle un significado a ese rango (0,4), diremos que:<br>\n",
    "`0` &rarr; Poco probable<br>\n",
    "`1` &rarr; Algo probable<br>\n",
    "`2` &rarr; Probable<br>\n",
    "`3` &rarr; Bastante probable<br>\n",
    "`4` &rarr; Muy probable<br>\n",
    "Para nuestro análisis binarizaremos la variable objetivo (**`target`**). Asignaremos como clase positiva `1` aquellos diagnósticos en los que el estrechamiento de arterias es superior al 50% (problemas graves de corazón) y le asignaremos la clase negativa `0` a aquellos casos en los que el estrechamiento de arterias sea inferior al 50% (ausencia de problemas de corazón).\n",
    "A continuación, analizaremos los atributos (features):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección I. Esquema lineal (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos todas las librerias que vamos a utilizar a lo largo de la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta primera sección vamos a hacer uso del modelo Support Vector Machine (SVM) considerando todas las características presentes en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los dataframes preprocesados en la tarea 1\n",
    "X_Diseño_preprocesado = pd.read_pickle('X_Diseño_preprocesado.pkl')\n",
    "X_test_preprocesado = pd.read_pickle('X_test_preprocesado.pkl')\n",
    "Y_Diseño = pd.read_pickle('Y_Diseño.pkl')\n",
    "Y_test = pd.read_pickle('Y_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lineal = SVC(kernel = 'linear')\n",
    "svm_lineal.fit(X_Diseño_preprocesado, Y_Diseño)\n",
    "coeff_svm_lineal = list(map(float,svm_lineal.coef_[0]))\n",
    "pairs = []\n",
    "for i in range(len(coeff_svm_lineal)):\n",
    "    pairs.append([coeff_svm_lineal[i],X_Diseño_preprocesado.columns[i]])\n",
    "pd.DataFrame(pairs, columns=['Coeff', 'Feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que los coeficientes que mas influyen en el target a la hora de clasificar son: <br>\n",
    "* **Positivamente a la clase 1:**  <br>\n",
    "    `1` ca : Número de vasos principales (0-3) coloreados por fluoroscopia <br>\n",
    "    `2` cp_4.0 : Tipo de dolor en el pecho (Asintomático) <br>\n",
    "    `3` thal_7.0 : Prueba de tálamo o tali (Efecto reversble) <br>\n",
    "* **Positivamente a la clase 0:**  <br>\n",
    "    `1` cp_1.0 : Tipo de dolor en el pecho (Angina típica) <br>\n",
    "    `2` thal_3.0 Prueba de tálamo o tali (Efecto fijo) : <br>\n",
    "    `3` slope_1.0 : La pendiente del segmento ST en el pico del ejercicio (Pendiente ascendente) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Coeficientes SVM lineal ?¿?¿??\n",
    "?¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿¿?¿??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia del escalado de los datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La normalizacion/estandarización de los datos para crear un modelo SVM es esencial. Esto se debe a que el modelo de SVM utiliza muestras del entrenamiento que llamaremos 'vectores soporte' para crear la frontera que  separa linealmente las clases y maximiza la distancia a estos puntos. Como hace uso de la distancia euclidea necesitamos estandarizar los datos para trabajar con las misma escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion con la regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_reg_log = [-0.11519437219116264,\n",
    " 0.566141608117244, \n",
    " 0.3099489241956889, \n",
    " -0.012310801030252373,\n",
    " -0.2759661876682957, \n",
    " -0.04660442981566006,\n",
    " 0.6435409647784468, \n",
    " 0.5140459080033545, \n",
    " 1.1380068486464945, \n",
    " -0.9828262177706325, \n",
    " 0.15509087190068083, \n",
    " -0.581341375932084, \n",
    " 1.2202274133609519, \n",
    " -0.3561452457617638, \n",
    " -0.012267781149770146,\n",
    " 0.17956371847045208, \n",
    " -0.5633388805305239, \n",
    " 0.5956251051994648, \n",
    " -0.22113553311002293,\n",
    " -0.6966608521082523, \n",
    " -0.17539205144422487,\n",
    " 0.6832035951113941]\n",
    "# Creamos el dataframe de comparacion\n",
    "coeff_comparacion = pd.DataFrame([coeff_reg_log], columns=X_Diseño_preprocesado.columns)\n",
    "coeff_comparacion.loc[len(coeff_comparacion)] = coeff_svm_lineal\n",
    "coeff_comparacion.loc[len(coeff_comparacion)] = abs(coeff_comparacion.iloc[0] - coeff_comparacion.iloc[1])\n",
    "coeff_comparacion = coeff_comparacion.T\n",
    "coeff_comparacion.columns = ['Coef_Regresion','Coef_SVM_lineal','Diferencia']\n",
    "coeff_comparacion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La svm en aproximadamente la mitad de los coeficientes apenas difiere con la regresión logística. En cuanto a los coeficientes más grandes, ambos modelos concuerdan en que los atributos más influyentes son:\n",
    "\n",
    "* **Positivamente a la clase 1:**  <br>\n",
    "     - thal_0.7  <br>\n",
    "     - cp_4.0  <br>\n",
    "     - ca  <br>\n",
    "* **Positivamente a la clase 0:**  <br>\n",
    "     - cp_1.0 <br>\n",
    "     - thal_3.0 <br>\n",
    "\n",
    "En la mayoría de coeficientes, ambos modelos, puesto que son similares, han llegado una conclusión similar. Algunas característica que parecía relevante con 1 modelo ha acabado siendo descartada como influyente, como por ejemplo slope_1.0, oldpeak o exang. Por otro lado, ambos modelos coinciden a la hora de poner coeficientes muy bajos a ciertos atributos, como restecg_1.0, cp_2.0, thalach o chol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prestaciones de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Ahora vamos a ver las prestaciones de ambos modelos para comparar los resultados y extraer conclusiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión logística\n",
    "modelo_RL = LogisticRegression(C=0.001, solver='newton-cg', penalty=None, random_state=314)\n",
    "modelo_RL.fit(X_Diseño_preprocesado, Y_Diseño)\n",
    "modelo_RL_predict = modelo_RL.predict(X_test_preprocesado)\n",
    "\n",
    "# SVM \n",
    "svm_lineal_predict = svm_lineal.predict(X_test_preprocesado)\n",
    "dif = (modelo_RL_predict!=svm_lineal_predict).sum()\n",
    "print(f\"Numero predicciones distintas: {dif}\")\n",
    "print(f\"Numero de observaciones: {X_test_preprocesado.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos modelos han predecido tan solo una observación distinta de 91 que hay en el conjunto de test, es decir, que sus prestaciones son practicamente idénticas. Ahora, comparemos directamente con las figuras de mérito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos las figuras de merito\n",
    "f1_lineal = f1_score(Y_test,svm_lineal_predict)\n",
    "acc_lineal = accuracy_score(Y_test,svm_lineal_predict)\n",
    "prec_lineal = precision_score(Y_test,svm_lineal_predict)\n",
    "recall_lineal = recall_score(Y_test,svm_lineal_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figuras_regresion_log = {\n",
    "'RegresionLogistica_reg':     [0.846154,\t0.815789,\t0.861111,\t0.775],\n",
    "'SVM Lineal': [acc_lineal,f1_lineal,prec_lineal,recall_lineal]\n",
    "}\n",
    "tabla_regresion_log = pd.DataFrame(figuras_regresion_log, index=['Accuracy', 'F1_score', 'Precisión', 'Recall'])\n",
    "tabla_regresion_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras calcular las figuras de mérito observamos que ambos modelos presentan unos resultados similares. Esto tiene sentido si tenemos en cuenta que ambos modelos tienen en comun 5 atributos como los mas relevantes/influyentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sección II. Esquema no lineal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las prestaciones del esquema lineal no son malas, pero no lo suficiente buenas como para asumir que es un problema linealmente separable por lo que probaremos 3 kernels no lineales, pero sin ajustar sus hiperparámetros todavía."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el conjunto de train y validacion\n",
    "X_train,X_val,Y_train ,Y_val= train_test_split(X_Diseño_preprocesado,Y_Diseño,random_state=314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos los diferentes modelos con distintos kernel\n",
    "kernels = ['linear', 'rbf', 'poly','sigmoid']\n",
    "figuras_merito = {}\n",
    "\n",
    "for kernel in kernels:\n",
    "    #Creamos el modelo y predecimos\n",
    "    svm_no_lineal = SVC(kernel = kernel,random_state=314)\n",
    "    svm_no_lineal.fit(X_train,Y_train)\n",
    "    prediccion = svm_no_lineal.predict(X_val)\n",
    "    #Hallamos las figuras de mérito\n",
    "    f1_kernel = f1_score(Y_val, prediccion)\n",
    "    acc_kernel = accuracy_score(Y_val, prediccion)\n",
    "    prec_kernel = precision_score(Y_val, prediccion)\n",
    "    recall_kernel = recall_score(Y_val, prediccion)\n",
    "    #Las guardamos en un diccionario\n",
    "    figuras_merito[kernel] = {}\n",
    "    figuras_merito[kernel]['f1_score'] = f1_kernel\n",
    "    figuras_merito[kernel]['accuracy'] = acc_kernel\n",
    "    figuras_merito[kernel]['precision'] = prec_kernel\n",
    "    figuras_merito[kernel]['recall'] = recall_kernel    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_figuras = pd.DataFrame(figuras_merito)\n",
    "df_figuras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando los kernel no lineales observamos mejores resultados que con el kernel lineal. El que produce mejores resultados es la **rbf**.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRIDSEARCH CROSS-VALIDATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver como varía el *recall* en función de los hiperparámetros del *kernel* con mejores prestaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_linear = {'C': np.linspace(0.01,40,20)}\n",
    "hp_rbf = {'C': np.linspace(0,10,11),'gamma': np.linspace(0.005,0.3,14)}\n",
    "hp_poly = {'C': np.linspace(0.01,30,10),'degree': [2,3,4],'gamma':  np.linspace(0.005,0.3,14)}\n",
    "hp_sigmoid = {'C': np.linspace(0.01,30,10),'gamma': np.linspace(0.001,0.1,10)}\n",
    "hiperparametros_kernels = []\n",
    "hiperparametros_kernels.append(hp_linear)\n",
    "hiperparametros_kernels.append(hp_rbf)\n",
    "hiperparametros_kernels.append(hp_poly)\n",
    "hiperparametros_kernels.append(hp_sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez guardado los valores de los hiperparámetros que vamos a utilizar usamos el método de *GridSearch* para buscar la mejor combinación de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busqueda de hiperparmáetros\n",
    "resultados = {}\n",
    "bestParams = {}\n",
    "bestScores = {}\n",
    "i = 0\n",
    "while i < len(hiperparametros_kernels):\n",
    "    SVM_cv = GridSearchCV(SVC(kernel=kernels[i],random_state=314),param_grid=hiperparametros_kernels[i],cv=4,scoring='recall',return_train_score=True)\n",
    "    SVM_cv.fit(X_Diseño_preprocesado,Y_Diseño)\n",
    "    resultados[kernels[i]] = SVM_cv.cv_results_\n",
    "    bestParams[kernels[i]] = SVM_cv.best_params_\n",
    "    bestScores[kernels[i]] = SVM_cv.best_score_\n",
    "    print(f\"Finished {kernels[i]}.\")\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a representar los resultados del kernel lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datos\n",
    "recall_scores_test = np.array(resultados['linear']['mean_test_score'], dtype=float)\n",
    "recall_scores_train = np.array(resultados['linear']['mean_train_score'], dtype=float)\n",
    "C_params = np.array(resultados['linear']['param_C'], dtype=float)\n",
    "\n",
    "# Crear la gráfica\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot para el recall de test\n",
    "plt.plot(C_params, recall_scores_test, color='red', linestyle='-', linewidth=2, label='Recall (Validation)', marker='o', markersize=6)\n",
    "\n",
    "# Plot para el recall de train\n",
    "plt.plot(C_params, recall_scores_train, color='blue', linestyle='--', linewidth=2, label='Recall (Train)', marker='s', markersize=6)\n",
    "\n",
    "# Agregar etiquetas y título\n",
    "plt.xlabel('C', fontsize=14)\n",
    "plt.ylabel('Recall', fontsize=14)\n",
    "plt.title('Recall en Train y Validation', fontsize=16)\n",
    "plt.legend()\n",
    "\n",
    "# Mejorar la apariencia\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)  # Mejorar el estilo de la rejilla\n",
    "plt.tight_layout()  # Ajustar el espaciado de la gráfica para que no se corte\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede apreciar que el modelo a partir de un C = 9, C = 11 el modelo ya estabiliza y no consigue mayores resultados, y como un mayor valor de C tiende a sobreajustar nos quedaremos con C = 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a representar los resultados utilizando como *kernel* la **RBF**. Para ello, debido a que tenemos 2 parametros a estimar, representaremos en 3 dimensiones y de varías formas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extraer los resultados del GridSearchCV para el kernel RBF\n",
    "kernel_rbf_results = resultados['rbf']  # Ajusta si la clave en tu diccionario es diferente\n",
    "\n",
    "# Extraer los valores de los hiperparámetros y el score\n",
    "C_values = kernel_rbf_results['param_C'].data  # Valores de C\n",
    "gamma_values = kernel_rbf_results['param_gamma'].data  # Valores de gamma\n",
    "recall_scores = kernel_rbf_results['mean_test_score']  # Recall medio\n",
    "\n",
    "# Asegurarse de convertir todo a arrays NumPy para trabajar más fácilmente\n",
    "C_values = np.array(C_values, dtype=float)\n",
    "gamma_values = np.array(gamma_values, dtype=float)\n",
    "recall_scores = np.array(recall_scores, dtype=float)\n",
    "\n",
    "# Crear una malla de C y gamma para el gráfico 3D\n",
    "C_unique = np.unique(C_values)\n",
    "gamma_unique = np.unique(gamma_values)\n",
    "\n",
    "# Reorganizar el score (recall) en formato de malla\n",
    "C_grid, gamma_grid = np.meshgrid(C_unique, gamma_unique)\n",
    "\n",
    "# Reshape del score para que coincida con la malla\n",
    "recall_grid = recall_scores.reshape(len(gamma_unique), len(C_unique))\n",
    "\n",
    "# Crear el gráfico 3D\n",
    "fig = plt.figure(figsize=(30, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Dibujar la superficie\n",
    "surf = ax.plot_surface(C_grid, gamma_grid, recall_grid, cmap='crest', edgecolor='k')\n",
    "\n",
    "ax.view_init(elev=30, azim=45)  # PARA ROTAR!!!\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Gamma')\n",
    "ax.set_zlabel('Recall')\n",
    "ax.set_title('Recall en validation')\n",
    "\n",
    "# Barra de colores para el score\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer resultados del GridSearchCV\n",
    "kernel_rbf_results = resultados['rbf'] \n",
    "\n",
    "# Extraer los valores de C, gamma y el score\n",
    "C_values = kernel_rbf_results['param_C'].data\n",
    "gamma_values = kernel_rbf_results['param_gamma'].data\n",
    "recall_scores = kernel_rbf_results['mean_test_score']\n",
    "\n",
    "# Creamos un DataFrame para facilitar el manejo de datos\n",
    "df = pd.DataFrame({\n",
    "    'C': C_values,\n",
    "    'Gamma': gamma_values,\n",
    "    'Recall': recall_scores\n",
    "})\n",
    "\n",
    "# Creamos una tabla pivotante para el heatmap\n",
    "pivot_table = df.pivot_table(index='Gamma', columns='C', values='Recall')\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(pivot_table, annot=True, cmap='coolwarm', fmt=\".3f\", cbar_kws={'label': 'Recall'})\n",
    "plt.title('Recall en validation')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Gamma')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_dark\"\n",
    "\n",
    "# Crear gráfico interactivo\n",
    "fig = go.Figure(data=[go.Surface(z=recall_grid, x=C_unique, y=gamma_unique, colorscale='Inferno')]) #Prueba con Inferno, Magma y Jet\n",
    "\n",
    "# Etiquetas\n",
    "fig.update_layout(\n",
    "    title='Recall en validation',\n",
    "    scene=dict(\n",
    "        xaxis_title='C',\n",
    "        yaxis_title='Gamma',\n",
    "        zaxis_title='Recall'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Crear DataFrame\n",
    "df_plotly = pd.DataFrame({\n",
    "    'C': C_values,\n",
    "    'Gamma': gamma_values,\n",
    "    'Recall': recall_scores\n",
    "})\n",
    "\n",
    "# Gráfico Scatter 3D interactivo\n",
    "fig = px.scatter_3d(df_plotly, x='C', y='Gamma', z='Recall', color='Recall', title='Recall en validation', color_continuous_scale='Jet')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras todas estas gráficas, vemos que ha una zona específica donde se obtienen los mayores valores de recall (por hacer una analogía, es una especie de \"meseta\"). A priori no hay preferencia en cuanto a que punto seleccionar, por lo que tomaremos uno relativamente central, contretamente el *C* = **4** y *gamma* = **0.021**, con un recall en validation de 0.85."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POLY KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el kernel **POLY** no podemos hacer una representacion debido a que tenemos 3 hiperparámetros que buscar, requeriríamos 4 dimensiones para esta tarea. Por lo tanto, vamos a seleccionar los mejores parametros que nos devuelve la funcion Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bestParams['poly'].keys())\n",
    "for p in list(bestParams['poly'].keys()):\n",
    "    print(p,\"->\",bestParams['poly'][p])\n",
    "\n",
    "print(\"Recall validation ->\",bestScores['poly'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos como mejores hiperparametros son *C* = **3.34**, *degree* = **3** y *gamma* = **0.016** con un recall de 0.838 en validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIGMOID KERNEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a representar los resultados utilizando como *kernel* la **SIGMOID**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Extraer los resultados del GridSearchCV para el kernel RBF\n",
    "kernel_sigmoid_results = resultados['sigmoid']  # Ajusta si la clave en tu diccionario es diferente\n",
    "\n",
    "# Extraer los valores de los hiperparámetros y el score\n",
    "C_values = kernel_sigmoid_results['param_C'].data  # Valores de C\n",
    "gamma_values = kernel_sigmoid_results['param_gamma'].data  # Valores de gamma\n",
    "recall_scores = kernel_sigmoid_results['mean_test_score']  # Recall medio\n",
    "\n",
    "# Asegurarse de convertir todo a arrays NumPy para trabajar más fácilmente\n",
    "C_values = np.array(C_values, dtype=float)\n",
    "gamma_values = np.array(gamma_values, dtype=float)\n",
    "recall_scores = np.array(recall_scores, dtype=float)\n",
    "\n",
    "# Crear una malla de C y gamma para el gráfico 3D\n",
    "C_unique = np.unique(C_values)\n",
    "gamma_unique = np.unique(gamma_values)\n",
    "\n",
    "# Reorganizar el score (recall) en formato de malla\n",
    "C_grid, gamma_grid = np.meshgrid(C_unique, gamma_unique)\n",
    "\n",
    "# Reshape del score para que coincida con la malla\n",
    "recall_grid = recall_scores.reshape(len(gamma_unique), len(C_unique))\n",
    "\n",
    "# Crear el gráfico 3D\n",
    "fig = plt.figure(figsize=(30, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Dibujar la superficie\n",
    "surf = ax.plot_surface(C_grid, gamma_grid, recall_grid, cmap='crest', edgecolor='k')\n",
    "\n",
    "ax.view_init(elev=30, azim=45)  # PARA ROTAR!!!\n",
    "\n",
    "# Etiquetas de los ejes\n",
    "ax.set_xlabel('C')\n",
    "ax.set_ylabel('Gamma')\n",
    "ax.set_zlabel('Recall')\n",
    "ax.set_title('Recall en validation')\n",
    "\n",
    "# Barra de colores para el score\n",
    "fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer resultados del GridSearchCV\n",
    "kernel_sigmoid_results = resultados['sigmoid']  # Asegúrate de que es el kernel correcto\n",
    "\n",
    "# Extraer los valores de C, gamma y el score\n",
    "C_values = kernel_sigmoid_results['param_C'].data\n",
    "gamma_values = kernel_sigmoid_results['param_gamma'].data\n",
    "recall_scores = kernel_sigmoid_results['mean_test_score']\n",
    "\n",
    "# Crear un DataFrame para facilitar el manejo de datos\n",
    "df = pd.DataFrame({\n",
    "    'C': C_values,\n",
    "    'Gamma': gamma_values,\n",
    "    'Recall': recall_scores\n",
    "})\n",
    "\n",
    "# Crear una tabla pivotante para el heatmap\n",
    "pivot_table = df.pivot_table(index='Gamma', columns='C', values='Recall')\n",
    "\n",
    "# Dibujar el heatmap con Seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(pivot_table, annot=True, cmap='coolwarm', fmt=\".3f\", cbar_kws={'label': 'Recall'})  # PRUEBA: coolwarm , YlOrRd , crest\n",
    "plt.title('Heatmap del Recall en función de C y Gamma (Kernel Sigmoid) para el conjunto de Validación')\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Gamma')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer resultados del GridSearchCV\n",
    "kernel_sigmoid_results = resultados['sigmoid']  # Asegúrate de que es el kernel correcto\n",
    "\n",
    "# Extraer los valores de C, gamma y el score\n",
    "C_values = kernel_sigmoid_results['param_C'].data\n",
    "gamma_values = kernel_sigmoid_results['param_gamma'].data\n",
    "recall_scores = kernel_sigmoid_results['mean_test_score']\n",
    "\n",
    "# Crear un DataFrame para facilitar el manejo de datos\n",
    "df = pd.DataFrame({\n",
    "    'C': C_values,\n",
    "    'Gamma': gamma_values,\n",
    "    'Recall': recall_scores\n",
    "})\n",
    "    \n",
    "# Crear un gráfico Scatter 3D interactivo con Plotly\n",
    "import plotly.express as px\n",
    "fig = px.scatter_3d(df, x='C', y='Gamma', z='Recall', color='Recall', \n",
    "                    title='Recall en función de C y Gamma (Kernel Sigmoid)', \n",
    "                    color_continuous_scale='Jet')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el kernel *sigmoid* hemos obtenido como mejores hiperparámetros *C* = **20** y *gamma* = **0.5** con un recall de 0.848 en validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitectura seleccionada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor kernel que hemos obtenido ha sido el **RBF** con un recall de 0.85, con los parametros *C* = **4** y *gamma* = **0.21**.\n",
    "\n",
    "Tras esto, vamos a testear el modelo con el conjunto de test para 4 figuras de mérito:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos y entrenamos el modelo\n",
    "svm_rbf = SVC(kernel = 'rbf', C = 4, gamma = 0.21, random_state=314)\n",
    "svm_rbf.fit(X_Diseño_preprocesado, Y_Diseño)\n",
    "\n",
    "# Prediccion\n",
    "svm_rbf_predict = svm_rbf.predict(X_test_preprocesado)\n",
    "\n",
    "#Obtenemos las figuras de merito\n",
    "f1_svmRBF = f1_score(Y_test,svm_rbf_predict)\n",
    "acc_svmRBF = accuracy_score(Y_test,svm_rbf_predict)\n",
    "prec_svmRBF = precision_score(Y_test,svm_rbf_predict)\n",
    "recall_svmRBF = recall_score(Y_test,svm_rbf_predict)\n",
    "\n",
    "print(f'F1-score : {f1_svmRBF}')\n",
    "print(f'Accuracy : {acc_svmRBF}')\n",
    "print(f'Precision : {prec_svmRBF}')\n",
    "print(f'Recall : {recall_svmRBF}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A la hora de evaluar el modelo, hemos obtenido unos resultado bastante inferiores a los obtenidos en la Tarea 1, parece que este modelo no nos va a servir del todo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
